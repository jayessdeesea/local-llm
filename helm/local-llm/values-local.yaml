frontend:
  name: frontend
  image:
    repository: ghcr.io/open-webui/open-webui
    tag: main
    pullPolicy: Always
  service:
    type: LoadBalancer
    port: 8080
  resources:
    limits:
      memory: "2Gi"
      cpu: "1"
    requests:
      memory: "1Gi"
      cpu: "500m"
  env:
    OLLAMA_API_BASE_URL: "http://ollama:11434"
    WEBUI_SECRET_KEY: "local-llm-secret"
    WEBUI_AUTH: "false"

ollama:
  name: ollama
  image:
    repository: ollama/ollama
    tag: latest
    pullPolicy: IfNotPresent
  models:
    - name: phi4
      pullOnStart: true
  service:
    type: LoadBalancer
    port: 11434
  resources:
    limits:
      memory: "32Gi"
      cpu: "8"
    requests:
      memory: "16Gi"
      cpu: "4"
  persistence:
    enabled: true
    size: 20Gi
    accessMode: ReadWriteOnce
